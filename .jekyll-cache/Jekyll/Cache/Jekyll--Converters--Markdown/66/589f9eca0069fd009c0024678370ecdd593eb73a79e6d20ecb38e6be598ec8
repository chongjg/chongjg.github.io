I"}
<p><strong>(持续更新中…)</strong></p>

<h2 id="telea">TELEA</h2>

<ul>
  <li>
    <p><strong>[原论文下载][1]；[带笔记论文下载][2]</strong></p>
  </li>
  <li>
    <p>（再也不脑抽用C++实现这种算法了</p>
  </li>
  <li>
    <p>这个算法是opencv自带的图像修复算法，直接说算法的流程吧：</p>
  </li>
</ul>

<h4 id="1区域划分">1.区域划分</h4>

<ul>
  <li>把每个像素标记为<strong>KNOWN、BAND、INSIDE</strong>三种</li>
</ul>

<ol>
  <li>
    <p><strong>INSIDE</strong>：待修复的像素，表示是待修复的块的内部像素。</p>
  </li>
  <li>
    <p><strong>BAND</strong>：与待修复的像素相邻的已知像素，表示块的边界。</p>
  </li>
  <li>
    <p><strong>KNOWN</strong>：其他已知像素。</p>
  </li>
</ol>

<p><img src="https://raw.githubusercontent.com/chongjg/chongjg.github.io/master/img/Image-Inpainting/inpainting-principle.png" alt="" /></p>

<ul>
  <li>如上图(a)所示，圈内是待修复部分<strong>INSIDE</strong>，圈外是已知部分<strong>KNOWN</strong>，圈就是<strong>BAND</strong>。</li>
</ul>

<h4 id="2修复单个像素">2.修复单个像素</h4>

<ul>
  <li>
    <p>考虑修复一个与<strong>BAND</strong>相邻的未知点<script type="math/tex">p</script>，如上图(b)所示，对于附近某一个已知(<strong>BAND和KNOWN</strong>)的点<script type="math/tex">q</script>，可以通过<script type="math/tex">p=I(q)+\Delta I(q)*(p-q)</script>来预测待修复点<script type="math/tex">p</script>。</p>
  </li>
  <li>
    <p>基于这个思路，可以以<script type="math/tex">p</script>为圆心<script type="math/tex">\varepsilon</script>为半径画一个圆，如上图(a)，圆内已知像素集合记为<script type="math/tex">B_\varepsilon(p)</script>，对于任意<script type="math/tex">q\in B_\varepsilon</script>都会对<script type="math/tex">I(p)</script>有一个预测值，对每一个预测赋予合适的权值<script type="math/tex">w(p,q)</script>，最后用归一化加权预测结果作为修复。</p>
  </li>
</ul>

<script type="math/tex; mode=display">I(p)=\frac{\underset{q\in B_\varepsilon(p)}{\sum}w(p,q)[I(q)+\Delta I(q)(p-q)]}{\underset{q\in B_\varepsilon(p)}{\sum} w(p,q)}</script>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1]:http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.98.5505&amp;rep=rep1&amp;type=pdf
[2]:https://github.com/chongjg/Image-Inpainting/blob/master/paper/An%20Image%20Inpainting%20Technique%20Based%20on%20the%20Fast%20Marching%20Method.pdf
[3]:https://www.math.ucla.edu/~bertozzi/papers/cvpr01.pdf
</code></pre></div></div>
:ET