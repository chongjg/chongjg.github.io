---
layout:     post                    # 使用的布局(不需要改)
title:      NNDL&机器学习笔记             # 标题 
subtitle:   记录新思想              #副标题
date:       2021-10-07              # 时间
author:     chongjg                 # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 学习笔记
---

NNDL《神经网络与深度学习》及西瓜书《机器学习》笔记  

[B站网课链接](https://www.bilibili.com/video/BV13b4y1177W?p=1)

[书、课件等](https://nndl.github.io/)

## NNDL&机器学习笔记





* 西瓜书《机器学习》

  * 第六章 支持向量机

    * 任意样本点$\mathbf x$到超平面$(\mathbf w,b)$的距离可写为
      $$
      |r|=\frac{|\mathbf w^\mathrm T\mathbf x+b|}{||\mathbf w||}
      $$
      **证明：**

      超平面方程：
      $$
      \mathbf w ^\mathrm T\mathbf x+b=0
      $$
      显然向量$\mathbf w$与该超平面垂直（向量$\mathbf t$与超平面平行充要条件为$\mathbf w^\mathrm T\mathbf t=0$）

      则有
      $$
      \mathbf w^\mathrm T(\mathbf x+r\frac{\mathbf w}{||\mathbf w||})+b=0\\
      r||\mathbf w||=-(\mathbf w^\mathrm T\mathbf x+b)
      $$
      

    * 支持向量机中的**核技巧应用**不是直接将样本从样本空间转换到特征空间，因为特征空间的维度可能很高，甚至是无穷维，为了避开这个障碍，不是直接进行转换，而是设置一个核函数表示两个样本在特征空间中的距离（不关注如何转换到特征空间）
      $$
      \kappa(\mathbf x_i,\mathbf x_j)=<\phi(\mathbf x_i),\phi(\mathbf x_j)>=\phi(\mathbf x_i)^\mathrm T\phi(\mathbf x_j)
      $$
      如高斯核：
      $$
      \kappa(\mathbf x_i,\mathbf x_j)=\exp(-\frac{||\mathbf x_i-\mathbf x_j||^2}{2\sigma^2})
      $$
      

    * 

